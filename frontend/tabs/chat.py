import streamlit as st
import api

def render_chat_tab(selected_kb):
    # 1. é¡¶éƒ¨é…ç½®åŒº
    col_s1, col_s2, col_s3 = st.columns([1, 1, 3])
    with col_s1:
        # [ä¿®æ”¹] æ·»åŠ æ¨¡å‹é€‰æ‹©
        llm_model = st.selectbox(
            "å¯¹è¯æ¨¡å‹", 
            ["qwen-flash", "qwen-plus", "qwen-max", "google/gemini-3-pro-preview-free"],
            index=0
        )
    with col_s2:
        strategy = st.selectbox("æ£€ç´¢ç­–ç•¥", ["default", "dense_only", "hybrid", "rerank"])
    with col_s3:
        use_stream = st.checkbox("æµå¼è¾“å‡º", value=True)
        # ç¨å¾®è°ƒæ•´ä¸€ä¸‹æ’ç‰ˆï¼Œè®©checkboxå‚ç›´å±…ä¸­
        st.write("") 
    
    if "messages" not in st.session_state:
        st.session_state.messages = []
        
    if st.button("ğŸ§¹ æ¸…ç©ºå¯¹è¯"):
        st.session_state.messages = []
        st.rerun()

    # 2. æ¸²æŸ“å†å²æ¶ˆæ¯
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
            if "sources" in msg and msg["sources"]:
                with st.expander(f"ğŸ“š å‚è€ƒäº† {len(msg['sources'])} ä¸ªåˆ‡ç‰‡"):
                    for idx, src in enumerate(msg["sources"]):
                        page_num = src.get("page_number")
                        page_info = f" (P{page_num})" if page_num else ""
                        st.markdown(f"**[{idx+1}] {src['source_filename']}{page_info}**")
                        st.caption(src['chunk_content'])

    # 3. å¤„ç†ç”¨æˆ·è¾“å…¥
    if prompt := st.chat_input("åœ¨è¿™ä¸ªçŸ¥è¯†åº“ä¸­æœç´¢..."):
        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # æ˜¾ç¤ºåŠ©æ‰‹å“åº”
        with st.chat_message("assistant"):
            payload = {
                "query": prompt,
                "knowledge_id": selected_kb['id'],
                "strategy": strategy,
                "llm_model": llm_model # [æ–°å¢] ä¼ é€’é€‰ä¸­çš„æ¨¡å‹
            }
            
            full_response = ""
            retrieved_sources = []

            # ================= A. æµå¼æ¨¡å¼ =================
            if use_stream:
                message_placeholder = st.empty()
                stream_gen = api.chat_stream(payload)
                
                for event in stream_gen:
                    if "error" in event:
                        message_placeholder.error(event["error"])
                        full_response = "Error"
                        break
                    
                    if event["type"] == "sources":
                        retrieved_sources = event["data"]
                    
                    elif event["type"] == "message":
                        full_response += event["data"]
                        message_placeholder.markdown(full_response + "â–Œ")
                
                if full_response != "Error":
                    message_placeholder.markdown(full_response)

            # ================= B. æ™®é€šæ¨¡å¼ =================
            else:
                with st.spinner(f"æ­£åœ¨æ€è€ƒ ({llm_model})..."):
                    success, data = api.chat_query(payload)
                    if success:
                        full_response = data["answer"]
                        retrieved_sources = data["sources"]
                        st.markdown(full_response)
                    else:
                        st.error(data)
                        full_response = "Error"

            # ================= å…¬å…±é€»è¾‘ï¼šæ˜¾ç¤ºæ¥æº =================
            if retrieved_sources:
                with st.expander(f"ğŸ“š å‚è€ƒäº† {len(retrieved_sources)} ä¸ªåˆ‡ç‰‡"):
                    for idx, src in enumerate(retrieved_sources):
                        page_num = src.get("page_number")
                        page_info = f" (P{page_num})" if page_num else ""
                        st.markdown(f"**[{idx+1}] {src['source_filename']}{page_info}**")
                        st.caption(src['chunk_content'])
            
            # æ›´æ–° Session State
            if full_response and full_response != "Error":
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": full_response,
                    "sources": retrieved_sources
                })