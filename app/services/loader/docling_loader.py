import logging
import torch
from typing import List, Optional
from pathlib import Path

# LangChain Document
from langchain_core.documents import Document

# Docling
from docling.document_converter import DocumentConverter, PdfFormatOption
from docling.datamodel.base_models import InputFormat
from docling.datamodel.pipeline_options import PdfPipelineOptions
from docling.datamodel.accelerator_options import AcceleratorOptions, AcceleratorDevice

logger = logging.getLogger(__name__)

class DoclingLoader:
    """
    åŸºäºŽ Docling çš„æ–‡æ¡£åŠ è½½å™¨ï¼Œæ”¯æŒ PDF å’Œ Docxã€‚
    è¾“å‡ºæ ¼å¼ä¸ºç»“æž„åŒ–çš„ Markdownã€‚
    """
    
    def __init__(self, file_path: str):
        self.file_path = file_path
        self._converter = self._init_converter()

    def _init_converter(self) -> DocumentConverter:
        """
        åˆå§‹åŒ– Converterï¼Œé…ç½® GPU åŠ é€Ÿï¼ˆå¦‚æžœå¯ç”¨ï¼‰
        """
        # é…ç½® Pipeline é€‰é¡¹
        pipeline_options = PdfPipelineOptions()
        pipeline_options.do_ocr = True  # å¼€å¯ OCR ä»¥å¤„ç†æ‰«æä»¶
        pipeline_options.do_table_structure = True # å¼€å¯è¡¨æ ¼ç»“æž„æå–

        # GPU åŠ é€Ÿé…ç½®
        if torch.cuda.is_available():
            logger.info("ðŸš€ Docling æ£€æµ‹åˆ° CUDA çŽ¯å¢ƒï¼Œæ­£åœ¨å¯ç”¨ GPU åŠ é€Ÿ...")
            pipeline_options.accelerator_options = AcceleratorOptions(
                num_threads=4, 
                device=AcceleratorDevice.CUDA
            )
        else:
            logger.warning("âš ï¸ æœªæ£€æµ‹åˆ° CUDAï¼ŒDocling å°†ä½¿ç”¨ CPU è¿è¡Œ (é€Ÿåº¦è¾ƒæ…¢)")
            pipeline_options.accelerator_options = AcceleratorOptions(
                num_threads=8, 
                device=AcceleratorDevice.CPU
            )

        # ç»‘å®šæ ¼å¼é…ç½®
        return DocumentConverter(
            format_options={
                InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)
            }
        )

    def load(self) -> List[Document]:
        """
        åŠ è½½æ–‡æ¡£å¹¶è½¬æ¢ä¸º LangChain Document å¯¹è±¡åˆ—è¡¨ã€‚
        ç›®å‰ Docling é€šå¸¸å°†æ•´ä¸ªæ–‡æ¡£è½¬æ¢ä¸ºä¸€ä¸ªå®Œæ•´çš„ Markdownï¼Œ
        è¿™é‡Œæˆ‘ä»¬å°†å…¶å°è£…ä¸ºä¸€ä¸ª Documentï¼ŒåŽç»­ç”± Splitter è¿›è¡Œåˆ‡åˆ†ã€‚
        """
        if not Path(self.file_path).exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {self.file_path}")

        logger.info(f"å¼€å§‹ä½¿ç”¨ Docling è§£æžæ–‡ä»¶: {self.file_path}")
        
        try:
            # æ ¸å¿ƒè½¬æ¢é€»è¾‘
            conversion_result = self._converter.convert(self.file_path)
            doc_content = conversion_result.document
            
            # å¯¼å‡ºä¸º Markdown
            markdown_text = doc_content.export_to_markdown()
            
            # æå–å…ƒæ•°æ®
            # Docling çš„å…ƒæ•°æ®å¯èƒ½æ¯”è¾ƒåˆ†æ•£ï¼Œæˆ‘ä»¬å–ä¸€äº›åŸºç¡€çš„
            metadata = {
                "source": str(self.file_path),
                "filename": Path(self.file_path).name,
                "page_count": len(doc_content.pages) if hasattr(doc_content, "pages") else 0,
                # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´å¤š Docling ç‰¹æœ‰çš„å…ƒæ•°æ®ï¼Œå¦‚è¡¨æ ¼æ•°é‡ç­‰
            }

            logger.info(f"Docling è§£æžå®Œæˆï¼Œç”Ÿæˆ Markdown é•¿åº¦: {len(markdown_text)}")
            
            return [Document(page_content=markdown_text, metadata=metadata)]

        except Exception as e:
            logger.error(f"Docling è§£æžå¤±è´¥: {e}", exc_info=True)
            raise e

# é€‚é…æ—§æœ‰ loader.py çš„æŽ¥å£é£Žæ ¼
def load_docling_document(file_path: str) -> List[Document]:
    loader = DoclingLoader(file_path)
    return loader.load()