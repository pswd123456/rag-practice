import logging
import torch
import json
import os
from typing import List
from pathlib import Path

# LangChain Document
from langchain_core.documents import Document

# Docling
from docling.document_converter import DocumentConverter, PdfFormatOption
from docling.datamodel.base_models import InputFormat
from docling.datamodel.pipeline_options import PdfPipelineOptions
from docling.datamodel.accelerator_options import AcceleratorOptions, AcceleratorDevice

# Config
from app.core.config import settings, PROJECT_ROOT  # ç¡®ä¿å¼•ç”¨äº† PROJECT_ROOT

logger = logging.getLogger(__name__)

class DoclingLoader:
    """
    åŸºäºŽ Docling çš„æ–‡æ¡£åŠ è½½å™¨ï¼Œæ”¯æŒ PDF å’Œ Docxã€‚
    è¾“å‡ºæ ¼å¼ä¸ºç»“æž„åŒ–çš„ Markdownã€‚
    """
    
    def __init__(self, file_path: str):
        self.file_path = file_path
        self._converter = self._init_converter()

    def _init_converter(self) -> DocumentConverter:
        """
        åˆå§‹åŒ– Converterï¼Œé…ç½® GPU åŠ é€Ÿï¼ˆå¦‚æžœå¯ç”¨ï¼‰
        """
        # é…ç½® Pipeline é€‰é¡¹
        pipeline_options = PdfPipelineOptions()
        pipeline_options.do_ocr = True  # å¼€å¯ OCR ä»¥å¤„ç†æ‰«æä»¶
        pipeline_options.do_table_structure = True # å¼€å¯è¡¨æ ¼ç»“æž„æå–

        # GPU åŠ é€Ÿé…ç½®
        if torch.cuda.is_available():
            logger.info("ðŸš€ Docling æ£€æµ‹åˆ° CUDA çŽ¯å¢ƒï¼Œæ­£åœ¨å¯ç”¨ GPU åŠ é€Ÿ...")
            pipeline_options.accelerator_options = AcceleratorOptions(
                num_threads=4, 
                device=AcceleratorDevice.CUDA
            )
        else:
            logger.warning("âš ï¸ æœªæ£€æµ‹åˆ° CUDAï¼ŒDocling å°†ä½¿ç”¨ CPU è¿è¡Œ (é€Ÿåº¦è¾ƒæ…¢)")
            pipeline_options.accelerator_options = AcceleratorOptions(
                num_threads=8, 
                device=AcceleratorDevice.CPU
            )

        # ç»‘å®šæ ¼å¼é…ç½®
        return DocumentConverter(
            format_options={
                InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)
            }
        )

    def _save_debug_files(self, doc_content, markdown_text: str):
        """
        [Debug Logic] ä¿å­˜ä¸­é—´è§£æžç»“æžœåˆ°é¡¹ç›®æ ¹ç›®å½•
        """
        try:
            # 1. æž„é€ æ–‡ä»¶å
            original_stem = Path(self.file_path).stem
            # æ¸…ç†æ–‡ä»¶åä¸­çš„ç‰¹æ®Šå­—ç¬¦ä»¥å…è·¯å¾„æŠ¥é”™
            safe_stem = "".join([c for c in original_stem if c.isalnum() or c in (' ', '-', '_')]).strip()
            
            json_filename = f"debug_docling_{safe_stem}.json"
            md_filename = f"debug_docling_{safe_stem}.md"
            
            json_path = PROJECT_ROOT / json_filename
            md_path = PROJECT_ROOT / md_filename

            logger.info(f"ðŸ› [Debug] æ­£åœ¨ä¿å­˜ Docling ä¸­é—´æ–‡ä»¶åˆ°æ ¹ç›®å½•...")

            # 2. ä¿å­˜å±‚çº§ç»“æž„ JSON (Hierarchical Structure)
            # DoclingDocument å¯¹è±¡é€šå¸¸æä¾› export_to_dict() æ–¹æ³•
            if hasattr(doc_content, "export_to_dict"):
                doc_dict = doc_content.export_to_dict()
                with open(json_path, "w", encoding="utf-8") as f:
                    json.dump(doc_dict, f, ensure_ascii=False, indent=2)
                logger.info(f"   -> JSON Structure: {json_path}")
            else:
                logger.warning("   -> è¯¥ Docling ç‰ˆæœ¬ä¸æ”¯æŒ export_to_dictï¼Œè·³è¿‡ JSON ä¿å­˜ã€‚")

            # 3. ä¿å­˜ Markdown å†…å®¹
            with open(md_path, "w", encoding="utf-8") as f:
                f.write(markdown_text)
            logger.info(f"   -> Markdown Content: {md_path}")

        except Exception as e:
            logger.error(f"ðŸ› [Debug] ä¿å­˜è°ƒè¯•æ–‡ä»¶å¤±è´¥: {e}", exc_info=True)

    def load(self) -> List[Document]:
        """
        åŠ è½½æ–‡æ¡£å¹¶è½¬æ¢ä¸º LangChain Document å¯¹è±¡åˆ—è¡¨ã€‚
        """
        if not Path(self.file_path).exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {self.file_path}")

        logger.info(f"å¼€å§‹ä½¿ç”¨ Docling è§£æžæ–‡ä»¶: {self.file_path}")
        
        try:
            # æ ¸å¿ƒè½¬æ¢é€»è¾‘
            conversion_result = self._converter.convert(self.file_path)
            doc_content = conversion_result.document
            
            # å¯¼å‡ºä¸º Markdown
            markdown_text = doc_content.export_to_markdown()

            # ==========================================
            # ðŸ› ï¸ æ’å…¥ Debug é€»è¾‘
            # ==========================================
            self._save_debug_files(doc_content, markdown_text)
            # ==========================================
            
            # æå–å…ƒæ•°æ®
            metadata = {
                "source": str(self.file_path),
                "filename": Path(self.file_path).name,
                "page_count": len(doc_content.pages) if hasattr(doc_content, "pages") else 0,
            }

            logger.info(f"Docling è§£æžå®Œæˆï¼Œç”Ÿæˆ Markdown é•¿åº¦: {len(markdown_text)}")
            
            return [Document(page_content=markdown_text, metadata=metadata)]

        except Exception as e:
            logger.error(f"Docling è§£æžå¤±è´¥: {e}", exc_info=True)
            raise e

# é€‚é…æ—§æœ‰ loader.py çš„æŽ¥å£é£Žæ ¼
def load_docling_document(file_path: str) -> List[Document]:
    loader = DoclingLoader(file_path)
    return loader.load()