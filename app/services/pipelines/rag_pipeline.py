# -*- coding: utf-8 -*-
"""
RAG ç®¡é“æ¨¡å— (pipeline.py)

è´Ÿè´£å®šä¹‰å’Œåˆ›å»º RAG (Retrieval-Augmented Generation) é“¾ã€‚
"""
import logging
from typing import AsyncGenerator, List, Optional, Union, Dict, Any

from langchain_core.documents import Document
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langfuse.langchain import CallbackHandler # ğŸŸ¢ å¼•å…¥ Handler

from app.services.generation.qa_service import QAService
from app.services.retrieval.retrieval_service import RetrievalService
from app.services.retrieval.vector_store_manager import VectorStoreManager
from app.services.factories.retrieval_factory import RetrievalFactory
from app.services.rerank.rerank_service import RerankService

logger = logging.getLogger(__name__)


class RAGPipeline:
    def __init__(self, 
                 retrieval_service: RetrievalService, 
                 qa_service: QAService,
                 rerank_service: RerankService

    ):
        """
        åˆå§‹åŒ– RAG ç®¡é“ï¼Œå°†æ£€ç´¢ä¸ç”ŸæˆèŒè´£è§£è€¦ã€‚
        """
        logger.debug("åˆå§‹åŒ– RAGPipeline...")
        self.retrieval_service = retrieval_service
        self.qa_service = qa_service
        self.rerank_service = rerank_service
        self.langfuse_handler = CallbackHandler()

        # [Pipeline èŒè´£]: ç¼–æ’ Retrieval å’Œ Generation
        # qa_service.chain æœŸæœ›æ¥æ”¶ Dict
        self.generation_chain = self.qa_service.chain
        
        retrieval_node = RunnableLambda(
            func = self.retrieval_service.fetch,
            afunc = self.retrieval_service.afetch
        )
        
        self.rag_chain = (
            {
                "context": retrieval_node | self._format_docs,
                "question": RunnablePassthrough(),
            }
            | self.generation_chain
        )

        logger.info("RAG ç®¡é“å·²æˆåŠŸåˆ›å»ºã€‚")

    @classmethod
    def build(
        cls,
        store_manager: VectorStoreManager,
        qa_service: QAService,
        rerank_service: RerankService, 
        knowledge_id: Optional[int] = None,
        recall_top_k: int = 50, 
        strategy: str = "hybrid", 
        **kwargs
    ) -> "RAGPipeline":
        """
        å·¥å‚æ–¹æ³•ï¼šç»„è£… RAGPipeline
        """
        
        retriever = RetrievalFactory.create_retriever(
            store_manager=store_manager,
            strategy=strategy,
            top_k=recall_top_k, 
            knowledge_id=knowledge_id,
            **kwargs
        )

        return cls(
            RetrievalService(retriever), 
            qa_service,
            rerank_service
        )

    def _format_docs(self, docs: List[Document]) -> str:
        logger.debug("æ­£åœ¨æ ¼å¼åŒ– %s ä¸ªæ£€ç´¢åˆ°çš„æ–‡æ¡£...", len(docs))
        formatted = "\n\n".join(doc.page_content for doc in docs)
        logger.debug("æ ¼å¼åŒ–åçš„ä¸Šä¸‹æ–‡é•¿åº¦: %s å­—ç¬¦", len(formatted))

        return "\n\n".join(doc.page_content for doc in docs)

    def _prepare_answer(self, inputs: Dict[str, Any], docs: List[Document]):
        """
        åŒæ­¥ç”Ÿæˆç­”æ¡ˆ
        :param inputs: åŒ…å«ç”¨æˆ·é—®é¢˜å’Œå…¶ä»–å˜é‡çš„å­—å…¸
        :param docs: æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨
        """
        # 1. æ ¼å¼åŒ–ä¸Šä¸‹æ–‡
        context = self._format_docs(docs)
        
        # 2. æ³¨å…¥ä¸Šä¸‹æ–‡å˜é‡
        # è¿™é‡Œçš„ copy æ˜¯ä¸ºäº†é¿å…å‰¯ä½œç”¨ä¿®æ”¹ä¼ å…¥çš„å­—å…¸
        final_inputs = inputs.copy()
        final_inputs["context"] = context
        
        # 3. è°ƒç”¨ GenerationNode
        answer = self.qa_service.invoke(final_inputs)
        return answer, docs

    async def _prepare_answer_async(self, inputs: Dict[str, Any], docs: List[Document]):
        """
        å¼‚æ­¥ç”Ÿæˆç­”æ¡ˆ
        """
        context = self._format_docs(docs)
        
        final_inputs = inputs.copy()
        final_inputs["context"] = context
        
        # æ³¨å…¥ Trace
        answer = await self.qa_service.ainvoke(
            final_inputs, 
            config={"callbacks": [self.langfuse_handler]}
        )
        return answer, docs

    # åŒæ­¥ query æ–¹æ³•æš‚ä¸æ”¯æŒ Rerank (å› ä¸º RerankService æ˜¯ async çš„)
    # å¦‚æœå¿…é¡»åŒæ­¥è°ƒç”¨ï¼Œéœ€ä½¿ç”¨ asyncio.run æˆ–é™çº§ä¸ºä»… Retrieve
    def query(self, question: str, **kwargs):
        """
        åŒæ­¥å…¥å£ (Legacy: æš‚ä¸æ”¯æŒ Rerankï¼Œç›´æ¥è¿”å› Retrieve ç»“æœ)
        """
        logger.warning("Synchronous query called. Reranking is skipped (Async required).")
        docs = self.retrieval_service.fetch(question)
        inputs = {"question": question, **kwargs}
        # ä½¿ç”¨ QAService çš„åŒæ­¥ invoke
        context = self._format_docs(docs)
        inputs["context"] = context
        answer = self.qa_service.invoke(inputs)
        return answer, docs

    async def async_query(self, question: str, top_k: int = 3, **kwargs):
        """
        å¼‚æ­¥å…¥å£ (Standard: Recall -> Rerank -> Generate)
        :param top_k: æœ€ç»ˆä¿ç•™ç»™ LLM çš„åˆ‡ç‰‡æ•°é‡ (Precision K)
        """
        # 1. Recall (æ£€ç´¢ 50 æ¡)
        # Retriever å·²ç»åœ¨ build æ—¶é…ç½®äº† RECALL_TOP_K
        recall_docs = await self.retrieval_service.afetch(
            question, 
            config={"callbacks": [self.langfuse_handler]}
        )
        
        # 2. Rerank (ç²¾æ’å– top_k)
        reranked_docs = await self.rerank_service.rerank_documents(
            query=question,
            docs=recall_docs,
            top_n=top_k
        )
        
        # 3. Generate
        inputs = {"question": question, **kwargs}
        return await self._prepare_answer_async(inputs, reranked_docs)

    async def astream_with_sources(self, query: str, top_k: int = 3, **kwargs) -> AsyncGenerator[Union[List[Document], str], None]:
        """
        æµå¼ç”Ÿæˆ (æ”¯æŒ Rerank)
        """
        # 1. Recall
        recall_docs = await self.retrieval_service.afetch(
            query,
            config={"callbacks": [self.langfuse_handler]}
        )
        
        # 2. Rerank
        reranked_docs = await self.rerank_service.rerank_documents(
            query=query,
            docs=recall_docs,
            top_n=top_k
        )
        
        # Yield ç²¾æ’åçš„æ–‡æ¡£
        yield reranked_docs
        
        # 3. Generate
        context = self._format_docs(reranked_docs)
        inputs = {"question": query, "context": context, **kwargs}
        
        async for token in self.generation_chain.astream(
            inputs,
            config={"callbacks": [self.langfuse_handler]}
        ):
            yield token
    def get_retrieval_service(self) -> RetrievalService:
        return self.retrieval_service

    def get_generation_chain(self):
        return self.generation_chain